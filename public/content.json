{"meta":{"title":"CODEMYMEMORY","subtitle":"如果你想为这世界做些什么，仅有理想是不够的，你需要找条通往目标的道路并走完。 -- 理查德·马修·斯托曼 (RMS)","description":"如果你想为这世界做些什么，仅有理想是不够的，你需要找条通往目标的道路并走完。 -- 理查德·马修·斯托曼 (RMS)","author":"凉小秋","url":"https://siogian.github.io"},"pages":[{"title":"about","date":"2018-09-30T07:59:25.000Z","updated":"2019-11-08T13:35:49.852Z","comments":true,"path":"about/index.html","permalink":"https://siogian.github.io/about/index.html","excerpt":"","text":""},{"title":"hao","date":"2019-11-10T15:14:38.000Z","updated":"2019-11-10T15:19:08.062Z","comments":true,"path":"hao/index.html","permalink":"https://siogian.github.io/hao/index.html","excerpt":"","text":"Baidu"}],"posts":[{"title":"Counter/Timer","slug":"Counter-Timer","date":"2019-11-09T02:50:07.000Z","updated":"2019-11-09T02:50:07.499Z","comments":true,"path":"2019/11/09/Counter-Timer/","link":"","permalink":"https://siogian.github.io/2019/11/09/Counter-Timer/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"金秋你好","slug":"hello-world","date":"2019-11-08T13:35:49.842Z","updated":"2019-11-08T13:35:49.842Z","comments":true,"path":"2019/11/08/hello-world/","link":"","permalink":"https://siogian.github.io/2019/11/08/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new &quot;My New Post&quot; More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"STM32CubeIDE - Show In System Explorer","slug":"STM32CubeIDE-Show-In-System-Explorer","date":"2019-09-13T00:51:02.000Z","updated":"2019-11-08T13:35:49.832Z","comments":true,"path":"2019/09/13/STM32CubeIDE-Show-In-System-Explorer/","link":"","permalink":"https://siogian.github.io/2019/09/13/STM32CubeIDE-Show-In-System-Explorer/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"6_041x 概率论——不确定性的科学","slug":"Overview","date":"2018-07-30T11:44:58.000Z","updated":"2019-11-08T13:35:49.817Z","comments":true,"path":"2018/07/30/Overview/","link":"","permalink":"https://siogian.github.io/2018/07/30/Overview/","excerpt":"","text":"Overview Overview Course introduction Course objectives A guide on how to use the wealth of available material Syllabus Course introductionWelcome to 6.041x, an introduction to probabilistic models, including random processes and the basic elements of statistical inference. The world is full of uncertainty: accidents, storms, unruly financial markets, noisy communications. The world is also full of data. Probabilistic modeling and the related field of statistical inference are the keys to analyzing data and making scientifically sound predictions. The course covers all of the basic probability concepts, including: multiple discrete or continuous random variables, expectations, and conditional distributions laws of large numbers the main tools of Bayesian inference methods an introduction to random processes (Poisson processes and Markov chains) Course objectivesUpon successful completion of this course, you will: At a conceptual level: Master the basic concepts associated with probability models. Be able to translate models described in words to mathematical ones. Understand the main concepts and assumptions underlying Bayesian and classical inference. Obtain some familiarity with the range of applications of inference methods. At a more technical level: Become familiar with basic and common probability distributions. Learn how to use conditioning to simplify the analysis of complicated models. Have facility manipulating probability mass functions, densities, and expectations. Develop a solid understanding of the concept of conditional expectation and its role in inference. Understand the power of laws of large numbers and be able to use them when appropriate. Become familiar with the basic inference methodologies (for both estimation and hypothesis testing) and be able to apply them. Acquire a good understanding of two stochastic processes and their use in modeling basic random phenomena: the Bernoulli process and the Poisson process. Learn how to formulate simple dynamical models as Markov chains and analyze them. A guide on how to use the wealth of available materialThis class provides you with a great wealth of material, perhaps more than you can fully digest. This “guide” offers some tips about how to use this material. Start with the overview of a unit, when available. This will help you get an overview of what is to happen next. Similarly, at the end of a unit, watch the unit summary to consolidate your understanding of the “big picture” and of the relation between different concepts. Watch the lecture videos. You may want to download the slides (clean or annotated) at the beginning of each lecture, especially if you cannot receive high-quality streaming video. Some of the lecture clips proceed at a moderate speed. Whenever you feel comfortable, you may want to speed up the video and run it faster, at 1.5x. Do the exercises! The exercises that follow most of the lecture clips are a most critical part of this class. Some of the exercises are simple adaptations of what you may have just heard. Other exercises will require more thought. Do your best to solve them right after each clip - do not defer this for later - so that you can consolidate your understanding. After your attempt, whether successful or not, do look at the solutions, which you will be able to see as soon as you submit your own answers. Solved problems and additional materials. In most of the units, we are providing you with many problems that are solved by members of our staff. We provide both video clips and written solutions. Depending on your learning style, you may pick and choose which format to focus on. But in either case, it is important that you get exposed to a large number of problems. The textbook. In the textbook you will sometimes find more precise statements of what was discussed in lecture, additional facts, as well as several examples. You should become familiar with its style and structure, and find the most effective way of using it. Problem sets. One can really master the subject only by solving problems - a large number of them. Some of the problems will be straightforward applications of what you have learned. A few of them will be more challenging. Do not despair if you cannot solve a problem - no one is expected to do everything perfectly. However, once the problem set solutions are released (which will happen on the due date of the problem set), make sure to go over the solutions to those problems that you could not solve correctly. Exams. The midterm exams are designed so that in an on-campus version, students would be given two hours. The final exam is designed so that in an on-campus version, students would be given three hours. You should not expect to spend much more than this amount of time on them. In this respect, those weeks that have exams (and no problem sets!) will not have higher demands on your time. The level of difficulty of exam questions will be somewhere between the lecture exercises and homework problems. Time management. The corresponding on-campus class is designed so that students spend about 12 hours each week on lectures, recitations, readings, and homework. You should expect a comparable effort. In a typical week, there will be 2 hours of lecture clips, but it might take you 4-5 hours when you add the time spent on exercises. Plan to spend another 3-4 hours watching solved problems and additional materials, and on textbook readings. Finally, expect about 4 hours spent on the weekly problem sets. Additional practice problems. For those of you who wish to dive even deeper into the subject, you can find a good collection of problems at the end of each chapter of the print edition of the book, whose solutions are available online. SyllabusUnit 0: Overview (released Fri. Jan 31) Unit 1: Probability models and axioms (released Tue. Feb 4; Sections 1.1-1.2)L1: Probability models and axiomsProblem Set 1 due on Feb 11 Unit 2: Conditioning and independence (released Mon. Feb 10; Sections 1.3-1.5)L2: Conditioning and Bayes’ ruleL3: IndependenceProblem Set 2 due on Feb 18 Unit 3: Counting (released Mon. Feb 17; Section 1.6)L4: CountingProblem Set 3 due on Feb 25 Unit 4: Discrete random variables (released Wed. Feb 19; Sections 2.1-2.7)L5: Probability mass functions and expectationsL6: Variance; Conditioning on an event; Multiple r.v.’sL7: Conditioning on a random variable; Independence of r.v.’sProblem Set 4 due on Mar 4 Exam 1: Covers material from L1 to L7 (released Wed. Mar 5; due on Mar 11) Unit 5: Continuous random variables (released Mon. Mar 3; Sections 3.1-3.5)L8: Probability density functionsL9: Conditioning on an event; Multiple r.v.’sL10: Conditioning on a random variable; Independence; Bayes’ ruleProblem Set 5 due on Mar 18 Unit 6: Further topics on random variables (released Mon. Mar 17; Sections 4.1-4.3, 4.5)L11: Derived distributionsL12: Sums of r.v.’s; Covariance and correlationL13: Conditional expectation and variance revisited; Sum of a random number of r.v.’sProblem Set 6 due on Apr 1 Unit 7: Bayesian inference (released Mon. Mar 31; Sections 3.6, 8.1-8.4)L14: Introduction to Bayesian inferenceL15: Linear models with normal noiseL16: Least mean squares (LMS) estimationL17: Linear least mean squares (LLMS) estimationProblem Set 7a due on Apr 8Problem Set 7b due on Apr 15 Exam 2: Covers material from L8 to L17 (released Wed. Apr 16; due on Apr 22) Unit 8: Limit theorems and classical statistics (released Mon. Apr 14; Sections 5.1-5.4, pp. 466-475)L18: Inequalities, convergence, and the Weak Law of Large NumbersL19: The Central Limit Theorem (CLT)L20: An introduction to classical statisticsProblem Set 8 due on Apr 29 Unit 9: Bernoulli and Poisson processes (released Wed. Apr 23; Sections 6.1-6-2)L21: The Bernoulli processL22: The Poisson processL23: More on the Poisson processProblem Set 9 due on May 6 Unit 10: Markov chains (released Mon. May 5; Sections 7.1-7-4)L24: Finite-state Markov chainsL25: Steady-state behavior of Markov chainsL26: Absorption probabilities and expected time to absorptionProblem Set 10 due on May 13 Final Exam (released Tue. May 13; due on May 20) *Note: Problem set and exam due dates are at the end of the specified date, at midnight UTC.","categories":[],"tags":[]}]}