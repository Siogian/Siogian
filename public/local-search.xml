<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Counter/Timer</title>
    <link href="undefined2019/11/09/Counter-Timer/"/>
    <url>2019/11/09/Counter-Timer/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>金秋你好</title>
    <link href="undefined2019/11/08/hello-world/"/>
    <url>2019/11/08/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>STM32CubeIDE - Show In System Explorer</title>
    <link href="undefined2019/09/13/STM32CubeIDE-Show-In-System-Explorer/"/>
    <url>2019/09/13/STM32CubeIDE-Show-In-System-Explorer/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>6_041x 概率论——不确定性的科学</title>
    <link href="undefined2018/07/30/Overview/"/>
    <url>2018/07/30/Overview/</url>
    
    <content type="html"><![CDATA[<h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><ul><li><a href="#overview">Overview</a><ul><li><a href="#course-introduction">Course introduction</a></li><li><a href="#course-objectives">Course objectives</a></li><li><a href="#a-guide-on-how-to-use-the-wealth-of-available-material">A guide on how to use the wealth of available material</a></li><li><a href="#syllabus">Syllabus</a></li></ul></li></ul><h2 id="Course-introduction"><a href="#Course-introduction" class="headerlink" title="Course introduction"></a>Course introduction</h2><p>Welcome to 6.041x, an introduction to probabilistic models, including random processes and the basic elements of statistical inference.</p><p>The world is full of uncertainty: accidents, storms, unruly financial markets, noisy communications. The world is also full of data. Probabilistic modeling and the related field of statistical inference are the keys to analyzing data and making scientifically sound predictions.</p><p>The course covers all of the basic probability concepts, including:</p><ul><li><p>multiple discrete or continuous random variables, expectations, and conditional distributions</p></li><li><p>laws of large numbers</p></li><li><p>the main tools of Bayesian inference methods</p></li><li><p>an introduction to random processes (Poisson processes and Markov chains) </p></li></ul><h2 id="Course-objectives"><a href="#Course-objectives" class="headerlink" title="Course objectives"></a>Course objectives</h2><p>Upon successful completion of this course, you will:</p><p>At a conceptual level:</p><ul><li><p>Master the basic concepts associated with probability models.</p></li><li><p>Be able to translate models described in words to mathematical ones.</p></li><li><p>Understand the main concepts and assumptions underlying Bayesian and classical inference.</p></li><li><p>Obtain some familiarity with the range of applications of inference methods. </p></li></ul><p>At a more technical level:</p><ul><li><p>Become familiar with basic and common probability distributions.</p></li><li><p>Learn how to use conditioning to simplify the analysis of complicated models.</p></li><li><p>Have facility manipulating probability mass functions, densities, and expectations.</p></li><li><p>Develop a solid understanding of the concept of conditional expectation and its role in inference.</p></li><li><p>Understand the power of laws of large numbers and be able to use them when appropriate.</p></li><li><p>Become familiar with the basic inference methodologies (for both estimation and hypothesis testing) and be able to apply them.</p></li><li><p>Acquire a good understanding of two stochastic processes and their use in modeling basic random phenomena: the Bernoulli process and the Poisson process.</p></li><li><p>Learn how to formulate simple dynamical models as Markov chains and analyze them. </p></li></ul><h2 id="A-guide-on-how-to-use-the-wealth-of-available-material"><a href="#A-guide-on-how-to-use-the-wealth-of-available-material" class="headerlink" title="A guide on how to use the wealth of available material"></a>A guide on how to use the wealth of available material</h2><p>This class provides you with a great wealth of material, perhaps more than you can fully digest. This “guide” offers some tips about how to use this material.</p><p><strong>Start with the overview of a unit,</strong> when available. This will help you get an overview of what is to happen next. Similarly, at the end of a unit, watch the <strong>unit summary</strong> to consolidate your understanding of the “big picture” and of the relation between different concepts.</p><p><strong>Watch the lecture videos.</strong> You may want to download the slides (clean or annotated) at the beginning of each lecture, especially if you cannot receive high-quality streaming video. Some of the lecture clips proceed at a moderate speed. Whenever you feel comfortable, you may want to speed up the video and run it faster, at 1.5x.</p><p><strong>Do the exercises!</strong> The exercises that follow most of the lecture clips are a most critical part of this class. Some of the exercises are simple adaptations of what you may have just heard. Other exercises will require more thought. Do your best to solve them right after each clip - do not defer this for later - so that you can consolidate your understanding. After your attempt, whether successful or not, do look at the solutions, which you will be able to see as soon as you submit your own answers.</p><p><strong>Solved problems and additional materials.</strong> In most of the units, we are providing you with many problems that are solved by members of our staff. We provide both video clips and written solutions. Depending on your learning style, you may pick and choose which format to focus on. But in either case, it is important that you get exposed to a large number of problems.</p><p><strong>The textbook.</strong> In the textbook you will sometimes find more precise statements of what was discussed in lecture, additional facts, as well as several examples. You should become familiar with its style and structure, and find the most effective way of using it.</p><p><strong>Problem sets.</strong> One can really master the subject only by solving problems - a large number of them. Some of the problems will be straightforward applications of what you have learned. A few of them will be more challenging. Do not despair if you cannot solve a problem - no one is expected to do everything perfectly. However, once the problem set solutions are released (which will happen on the due date of the problem set), make sure to go over the solutions to those problems that you could not solve correctly.</p><p><strong>Exams.</strong> The midterm exams are designed so that in an on-campus version, students would be given two hours. The final exam is designed so that in an on-campus version, students would be given three hours. You should not expect to spend much more than this amount of time on them. In this respect, those weeks that have exams (and no problem sets!) will not have higher demands on your time. The level of difficulty of exam questions will be somewhere between the lecture exercises and homework problems.</p><p><strong>Time management.</strong> The corresponding on-campus class is designed so that students spend about 12 hours each week on lectures, recitations, readings, and homework. You should expect a comparable effort. In a typical week, there will be 2 hours of lecture clips, but it might take you 4-5 hours when you add the time spent on exercises. Plan to spend another 3-4 hours watching solved problems and additional materials, and on textbook readings. Finally, expect about 4 hours spent on the weekly problem sets.</p><p><strong>Additional practice problems.</strong> For those of you who wish to dive even deeper into the subject, you can find a good collection of problems at the end of each chapter of the print edition of the book, whose solutions are available online. </p><h2 id="Syllabus"><a href="#Syllabus" class="headerlink" title="Syllabus"></a>Syllabus</h2><p><strong>Unit 0: Overview</strong> (released Fri. Jan 31)</p><p><strong>Unit 1: Probability models and axioms</strong> (released Tue. Feb 4; Sections 1.1-1.2)<br>L1: Probability models and axioms<br>Problem Set 1 due on Feb 11</p><p><strong>Unit 2: Conditioning and independence</strong> (released Mon. Feb 10; Sections 1.3-1.5)<br>L2: Conditioning and Bayes’ rule<br>L3: Independence<br>Problem Set 2 due on Feb 18</p><p><strong>Unit 3: Counting</strong> (released Mon. Feb 17; Section 1.6)<br>L4: Counting<br>Problem Set 3 due on Feb 25</p><p><strong>Unit 4: Discrete random variables</strong> (released Wed. Feb 19; Sections 2.1-2.7)<br>L5: Probability mass functions and expectations<br>L6: Variance; Conditioning on an event; Multiple r.v.’s<br>L7: Conditioning on a random variable; Independence of r.v.’s<br>Problem Set 4 due on Mar 4</p><p><strong>Exam 1: Covers material from L1 to L7</strong> (released Wed. Mar 5; due on Mar 11)</p><p><strong>Unit 5: Continuous random variables</strong> (released Mon. Mar 3; Sections 3.1-3.5)<br>L8: Probability density functions<br>L9: Conditioning on an event; Multiple r.v.’s<br>L10: Conditioning on a random variable; Independence; Bayes’ rule<br>Problem Set 5 due on Mar 18</p><p><strong>Unit 6: Further topics on random variables</strong> (released Mon. Mar 17; Sections 4.1-4.3, 4.5)<br>L11: Derived distributions<br>L12: Sums of r.v.’s; Covariance and correlation<br>L13: Conditional expectation and variance revisited; Sum of a random number of r.v.’s<br>Problem Set 6 due on Apr 1</p><p><strong>Unit 7: Bayesian inference</strong> (released Mon. Mar 31; Sections 3.6, 8.1-8.4)<br>L14: Introduction to Bayesian inference<br>L15: Linear models with normal noise<br>L16: Least mean squares (LMS) estimation<br>L17: Linear least mean squares (LLMS) estimation<br>Problem Set 7a due on Apr 8<br>Problem Set 7b due on Apr 15</p><p><strong>Exam 2: Covers material from L8 to L17</strong> (released Wed. Apr 16; due on Apr 22)</p><p><strong>Unit 8: Limit theorems and classical statistics</strong> (released Mon. Apr 14; Sections 5.1-5.4, pp. 466-475)<br>L18: Inequalities, convergence, and the Weak Law of Large Numbers<br>L19: The Central Limit Theorem (CLT)<br>L20: An introduction to classical statistics<br>Problem Set 8 due on Apr 29</p><p><strong>Unit 9: Bernoulli and Poisson processes</strong> (released Wed. Apr 23; Sections 6.1-6-2)<br>L21: The Bernoulli process<br>L22: The Poisson process<br>L23: More on the Poisson process<br>Problem Set 9 due on May 6</p><p><strong>Unit 10: Markov chains</strong> (released Mon. May 5; Sections 7.1-7-4)<br>L24: Finite-state Markov chains<br>L25: Steady-state behavior of Markov chains<br>L26: Absorption probabilities and expected time to absorption<br>Problem Set 10 due on May 13</p><p><strong>Final Exam</strong> (released Tue. May 13; due on May 20)</p><p><strong>*Note: Problem set and exam due dates are at the end of the specified date, at midnight UTC.</strong></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>